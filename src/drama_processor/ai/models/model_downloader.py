"""AIæ¨¡å‹ä¸‹è½½å’Œç®¡ç†å·¥å…·"""

import os
import hashlib
from pathlib import Path
from typing import Dict, Optional
import requests
from urllib.parse import urlparse

class ModelDownloader:
    """AIæ¨¡å‹ä¸‹è½½å’Œç¼“å­˜ç®¡ç†"""
    
    # é¢„å®šä¹‰çš„æ¨¡å‹é…ç½®
    MODEL_CONFIGS = {
        # è½»é‡çº§åœºæ™¯æ£€æµ‹æ¨¡å‹
        "scene_classifier": {
            "url": "https://github.com/opencv/opencv_zoo/raw/main/models/image_classification_mobilenet/image_classification_mobilenetv1_224x224.onnx",
            "filename": "mobilenet_scene_classifier.onnx",
            "sha256": "placeholder_hash",  # å®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®hash
            "description": "MobileNetåœºæ™¯åˆ†ç±»æ¨¡å‹"
        },
        
        # å†…å®¹å®‰å…¨æ£€æµ‹æ¨¡å‹
        "content_safety": {
            "url": "https://huggingface.co/martin-ha/toxic-comment-model/resolve/main/pytorch_model.bin",
            "filename": "content_safety_model.bin",
            "sha256": "placeholder_hash",
            "description": "å†…å®¹å®‰å…¨æ£€æµ‹æ¨¡å‹"
        },
        
        # è½»é‡çº§ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆæ£€æµ‹äººç‰©ã€ç‰©ä½“ç­‰ï¼‰
        "object_detection": {
            "url": "https://github.com/opencv/opencv_zoo/raw/main/models/object_detection_yolox/object_detection_yolox_2022nov.onnx",
            "filename": "yolox_nano.onnx", 
            "sha256": "placeholder_hash",
            "description": "YOLOXè½»é‡çº§ç›®æ ‡æ£€æµ‹æ¨¡å‹"
        }
    }
    
    def __init__(self, cache_dir: Optional[str] = None):
        """åˆå§‹åŒ–æ¨¡å‹ä¸‹è½½å™¨
        
        Args:
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º ~/.drama_processor/models
        """
        if cache_dir is None:
            cache_dir = os.path.expanduser("~/.drama_processor/models")
        
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def download_model(self, model_name: str, force_download: bool = False) -> Path:
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Raises:
            ValueError: æœªçŸ¥æ¨¡å‹åç§°
            RuntimeError: ä¸‹è½½å¤±è´¥
        """
        if model_name not in self.MODEL_CONFIGS:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}ã€‚å¯ç”¨æ¨¡å‹: {list(self.MODEL_CONFIGS.keys())}")
        
        config = self.MODEL_CONFIGS[model_name]
        model_path = self.cache_dir / config["filename"]
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ•ˆ
        if model_path.exists() and not force_download:
            if self._verify_file_integrity(model_path, config.get("sha256")):
                print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_path}")
                return model_path
            else:
                print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶æŸåï¼Œé‡æ–°ä¸‹è½½: {model_path}")
        
        # ä¸‹è½½æ¨¡å‹
        print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {config['description']}")
        print(f"   URL: {config['url']}")
        print(f"   ä¿å­˜åˆ°: {model_path}")
        
        try:
            self._download_file(config["url"], model_path)
            
            # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
            if config.get("sha256") and not self._verify_file_integrity(model_path, config["sha256"]):
                model_path.unlink()  # åˆ é™¤æŸåçš„æ–‡ä»¶
                raise RuntimeError(f"ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶æ ¡éªŒå¤±è´¥: {model_name}")
            
            print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            return model_path
            
        except Exception as e:
            if model_path.exists():
                model_path.unlink()  # æ¸…ç†å¤±è´¥çš„ä¸‹è½½
            raise RuntimeError(f"æ¨¡å‹ä¸‹è½½å¤±è´¥ {model_name}: {e}")
    
    def _download_file(self, url: str, output_path: Path) -> None:
        """ä¸‹è½½æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„"""
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)
                    
                    # ç®€å•çš„è¿›åº¦æ˜¾ç¤º
                    if total_size > 0:
                        progress = (downloaded_size / total_size) * 100
                        print(f"\r   è¿›åº¦: {progress:.1f}%", end='', flush=True)
        
        print()  # æ¢è¡Œ
    
    def _verify_file_integrity(self, file_path: Path, expected_hash: Optional[str]) -> bool:
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        if not expected_hash or expected_hash == "placeholder_hash":
            return True  # è·³è¿‡å ä½ç¬¦hashçš„éªŒè¯
        
        if not file_path.exists():
            return False
        
        # è®¡ç®—æ–‡ä»¶SHA256
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        
        return sha256_hash.hexdigest() == expected_hash
    
    def list_available_models(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        return {name: config["description"] for name, config in self.MODEL_CONFIGS.items()}
    
    def get_model_path(self, model_name: str) -> Optional[Path]:
        """è·å–æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœå·²ä¸‹è½½ï¼‰"""
        if model_name not in self.MODEL_CONFIGS:
            return None
        
        model_path = self.cache_dir / self.MODEL_CONFIGS[model_name]["filename"]
        return model_path if model_path.exists() else None


def main():
    """å‘½ä»¤è¡Œå·¥å…·ï¼šä¸‹è½½æ¨¡å‹"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¸‹è½½AIæ¨¡å‹")
    parser.add_argument("model_name", help="æ¨¡å‹åç§°")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ä¸‹è½½")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºå¯ç”¨æ¨¡å‹")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader()
    
    if args.list:
        print("å¯ç”¨æ¨¡å‹:")
        for name, desc in downloader.list_available_models().items():
            print(f"  {name}: {desc}")
        return
    
    try:
        model_path = downloader.download_model(args.model_name, args.force)
        print(f"æ¨¡å‹å·²å‡†å¤‡å°±ç»ª: {model_path}")
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        exit(1)


if __name__ == "__main__":
    main()

"""AIå¢å¼ºçš„çŸ­å‰§å¤„ç†å™¨"""

import logging
import random
import json
from pathlib import Path
from typing import List, Optional, Tuple, Dict, Any
import time
import hashlib

from ..core.processor import DramaProcessor
from ..models.config import ProcessingConfig
from ..models.project import DramaProject
from ..models.episode import Episode

from .scene_detection.scene_analyzer import SceneAnalyzer, OptimalCutPoint

logger = logging.getLogger(__name__)


class AIEnhancedProcessor(DramaProcessor):
    """AIå¢å¼ºçš„çŸ­å‰§å¤„ç†å™¨"""
    
    def __init__(self, config: ProcessingConfig,
                 enable_ai_scene_detection: bool = True,
                 status_callback=None):
        """åˆå§‹åŒ–AIå¢å¼ºå¤„ç†å™¨
        
        Args:
            config: å¤„ç†é…ç½®
            enable_ai_scene_detection: æ˜¯å¦å¯ç”¨AIåœºæ™¯æ£€æµ‹
            status_callback: çŠ¶æ€å›è°ƒå‡½æ•°
        """
        super().__init__(config, status_callback)
        
        self.enable_scene_detection = enable_ai_scene_detection
        
        # å»é‡åŠŸèƒ½é…ç½®
        self.enable_deduplication = config.enable_deduplication
        
        # ç”¨äºé¿å…é‡å¤çš„å…¨å±€å‰ªè¾‘ç‚¹è®°å½•ï¼ˆä»…åœ¨å¯ç”¨å»é‡æ—¶ä½¿ç”¨ï¼‰
        self.used_cut_points = []  # List[Tuple[int, float]] - (episode_idx, timestamp)
        self.exclusion_radius = 30.0  # æ’é™¤åŠå¾„ï¼š30ç§’
        
        # æŒä¹…åŒ–å­˜å‚¨é…ç½®ï¼ˆä»…åœ¨å¯ç”¨å»é‡æ—¶åˆå§‹åŒ–ï¼‰
        if self.enable_deduplication:
            self.cut_points_storage_dir = Path(config.temp_dir or "/tmp") / "cut_points_history"
            self.cut_points_storage_dir.mkdir(parents=True, exist_ok=True)
        else:
            self.cut_points_storage_dir = None
        
        # åˆå§‹åŒ–AIç»„ä»¶
        if self.enable_scene_detection:
            logger.info("æ­£åœ¨åˆå§‹åŒ–AIæ™ºèƒ½åœºæ™¯æ£€æµ‹ç»„ä»¶...")
            self.scene_analyzer = SceneAnalyzer()
            logger.info("AIæ™ºèƒ½åœºæ™¯æ£€æµ‹å·²å¯ç”¨")
        else:
            self.scene_analyzer = None
            logger.info("AIåœºæ™¯æ£€æµ‹å·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿå¤„ç†æ–¹å¼")
    
    def _get_drama_hash(self, drama_name: str) -> str:
        """ç”Ÿæˆå‰§é›†çš„å”¯ä¸€æ ‡è¯†ç¬¦"""
        return hashlib.md5(drama_name.encode('utf-8')).hexdigest()[:8]
    
    def _get_cut_points_file(self, drama_name: str) -> Path:
        """è·å–å‰ªè¾‘ç‚¹å­˜å‚¨æ–‡ä»¶è·¯å¾„"""
        if not self.enable_deduplication or not self.cut_points_storage_dir:
            raise ValueError("å»é‡åŠŸèƒ½æœªå¯ç”¨")
        
        drama_hash = self._get_drama_hash(drama_name)
        return self.cut_points_storage_dir / f"{drama_hash}_{drama_name}.json"
    
    def _load_used_cut_points(self, drama_name: str) -> List[Tuple[int, float]]:
        """ä»æ–‡ä»¶åŠ è½½å·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹"""
        if not self.enable_deduplication:
            return []
        
        try:
            cut_points_file = self._get_cut_points_file(drama_name)
            if not cut_points_file.exists():
                return []
            
            with open(cut_points_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # è½¬æ¢ä¸ºå…ƒç»„åˆ—è¡¨
            used_points = [(item['episode_idx'], item['timestamp']) for item in data.get('used_cut_points', [])]
            logger.info(f"ä»æ–‡ä»¶åŠ è½½äº† {len(used_points)} ä¸ªå·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹ï¼š{drama_name}")
            return used_points
            
        except Exception as e:
            logger.warning(f"åŠ è½½å‰ªè¾‘ç‚¹æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return []
    
    def _save_used_cut_points(self, drama_name: str, cut_points: List[Tuple[int, float]]):
        """ä¿å­˜å·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹åˆ°æ–‡ä»¶"""
        if not self.enable_deduplication:
            return
        
        try:
            cut_points_file = self._get_cut_points_file(drama_name)
            
            # å‡†å¤‡æ•°æ®ç»“æ„
            from datetime import datetime
            data = {
                'drama_name': drama_name,
                'last_updated': datetime.now().isoformat(),
                'used_cut_points': [
                    {'episode_idx': ep_idx, 'timestamp': ts} 
                    for ep_idx, ts in cut_points
                ]
            }
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            cut_points_file.parent.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶
            with open(cut_points_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"å·²ä¿å­˜ {len(cut_points)} ä¸ªå‰ªè¾‘ç‚¹åˆ°æ–‡ä»¶ï¼š{drama_name}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å‰ªè¾‘ç‚¹æ–‡ä»¶å¤±è´¥ï¼š{e}")
    
    def _add_used_cut_point(self, episode_idx: int, timestamp: float):
        """æ·»åŠ ä¸€ä¸ªå·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹"""
        if not self.enable_deduplication:
            return
        
        self.used_cut_points.append((episode_idx, timestamp))
        logger.debug(f"æ·»åŠ å·²ä½¿ç”¨å‰ªè¾‘ç‚¹: Episode {episode_idx}, {timestamp:.1f}s")

    def _is_cut_point_excluded(self, episode_idx: int, timestamp: float) -> bool:
        """æ£€æŸ¥å‰ªè¾‘ç‚¹æ˜¯å¦åœ¨æ’é™¤åŒºåŸŸå†…"""
        for used_ep_idx, used_timestamp in self.used_cut_points:
            if used_ep_idx == episode_idx:
                # åŒä¸€é›†å†…æ£€æŸ¥æ—¶é—´è·ç¦»
                if abs(timestamp - used_timestamp) < self.exclusion_radius:
                    return True
        return False
    
    def process_project_materials(self, project: DramaProject, out_dir: str, 
                                run_suffix: Optional[str], start_index: int, 
                                total_to_make: int, temp_root: str, drama_date: Optional[str] = None) -> Tuple[int, float]:
        """å¤„ç†é¡¹ç›®ç´ æï¼Œæ”¯æŒå»é‡åŠŸèƒ½
        
        åœ¨å¤„ç†å‰åŠ è½½å†å²å‰ªè¾‘ç‚¹ï¼Œå¤„ç†åä¿å­˜æ–°çš„å‰ªè¾‘ç‚¹
        """
        # åœ¨å¯ç”¨å»é‡æ—¶ï¼ŒåŠ è½½å†å²å‰ªè¾‘ç‚¹
        if self.enable_deduplication:
            logger.info(f"ğŸ”„ å¯ç”¨å»é‡æ¨¡å¼ï¼ŒåŠ è½½å†å²å‰ªè¾‘ç‚¹ï¼š{project.name}")
            historical_points = self._load_used_cut_points(project.name)
            self.used_cut_points.extend(historical_points)
            
            if historical_points:
                logger.info(f"âœ… å·²åŠ è½½ {len(historical_points)} ä¸ªå†å²å‰ªè¾‘ç‚¹")
            else:
                logger.info("ğŸ“ æœªå‘ç°å†å²å‰ªè¾‘ç‚¹ï¼Œå¼€å§‹æ–°è®°å½•")
        
        # è®°å½•å¤„ç†å‰çš„å‰ªè¾‘ç‚¹æ•°é‡
        initial_points_count = len(self.used_cut_points)
        
        # è°ƒç”¨çˆ¶ç±»çš„å¤„ç†æ–¹æ³•
        completed_count, total_time = super().process_project_materials(
            project, out_dir, run_suffix, start_index, total_to_make, temp_root, drama_date
        )
        
        # åœ¨å¯ç”¨å»é‡æ—¶ï¼Œä¿å­˜æ–°å¢çš„å‰ªè¾‘ç‚¹
        if self.enable_deduplication and completed_count > 0:
            new_points_count = len(self.used_cut_points) - initial_points_count
            if new_points_count > 0:
                logger.info(f"ğŸ’¾ ä¿å­˜æ–°å¢çš„ {new_points_count} ä¸ªå‰ªè¾‘ç‚¹")
                self._save_used_cut_points(project.name, self.used_cut_points)
            else:
                logger.info("ğŸ” æœªç”Ÿæˆæ–°çš„å‰ªè¾‘ç‚¹")
        
        return completed_count, total_time
    
    def generate_start_points(self, project: DramaProject, count: int) -> List[Tuple[int, float]]:
        """ç”Ÿæˆèµ·å§‹ç‚¹ï¼Œæ”¯æŒå»é‡å’ŒAIåœºæ™¯æ£€æµ‹"""
        if count <= 0:
            return []
        
        logger.info(f"ğŸ¯ å¼€å§‹ç”Ÿæˆ {count} ä¸ªèµ·å§‹ç‚¹")
        
        # å¦‚æœå¯ç”¨AIåœºæ™¯æ£€æµ‹ï¼Œä½¿ç”¨AIæ–¹æ³•
        if self.enable_scene_detection and self.scene_analyzer:
            return self._generate_ai_start_points(project, count)
        
        # å¦åˆ™ä½¿ç”¨çˆ¶ç±»çš„éšæœºæ–¹æ³•ï¼Œä½†åŠ ä¸Šå»é‡é€»è¾‘
        return self._generate_random_start_points_with_dedup(project, count)
    
    def _generate_ai_start_points(self, project: DramaProject, count: int) -> List[Tuple[int, float]]:
        """ä½¿ç”¨AIç”Ÿæˆèµ·å§‹ç‚¹ - ä»éšæœºé€‰æ‹©çš„é›†æ•°å¼€å§‹åˆ†æ"""
        if not project.episodes:
            return []
        
        start_points = []
        num_episodes = len(project.episodes)
        
        try:
            # ä¸ºæ¯ä¸ªç´ æç‹¬ç«‹é€‰æ‹©éšæœºèµ·å§‹é›†å’ŒAIå‰ªè¾‘ç‚¹
            for material_idx in range(count):
                # éšæœºé€‰æ‹©èµ·å§‹é›†æ•°
                random_ep_idx = random.randrange(num_episodes)
                
                # ä½¿ç”¨AIåˆ†æè¯¥é›†æ•°æ‰¾åˆ°æœ€ä½³å‰ªè¾‘ç‚¹
                optimal_points = self._find_optimal_segments_with_ai_for_episode(project, random_ep_idx)
                
                if optimal_points:
                    # åº”ç”¨å»é‡é€»è¾‘è¿‡æ»¤å·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹
                    if self.enable_deduplication:
                        filtered_points = []
                        for point in optimal_points:
                            if not self._is_cut_point_excluded(random_ep_idx, point.timestamp):
                                filtered_points.append(point)
                            else:
                                logger.debug(f"è·³è¿‡å·²ä½¿ç”¨çš„AIå‰ªè¾‘ç‚¹: ç¬¬{random_ep_idx+1}é›† {point.timestamp:.1f}s")
                        
                        if filtered_points:
                            optimal_points = filtered_points
                        else:
                            # å¦‚æœè¯¥é›†çš„AIå‰ªè¾‘ç‚¹éƒ½è¢«ä½¿ç”¨äº†ï¼Œå›é€€åˆ°è¯¥é›†çš„éšæœºç‚¹
                            logger.debug(f"ç¬¬{random_ep_idx+1}é›†çš„AIå‰ªè¾‘ç‚¹éƒ½å·²ä½¿ç”¨ï¼Œä½¿ç”¨éšæœºç‚¹")
                            optimal_points = None
                
                if optimal_points:
                    # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„å‰ªè¾‘ç‚¹
                    best_point = max(optimal_points, key=lambda p: p.confidence)
                    start_points.append((random_ep_idx, best_point.timestamp))
                    
                    # è®°å½•å·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹
                    if self.enable_deduplication:
                        self._add_used_cut_point(random_ep_idx, best_point.timestamp)
                    
                    logger.info(f"âœ… AIé€‰æ‹©å‰ªè¾‘ç‚¹: ç¬¬{random_ep_idx+1}é›†, {best_point.timestamp:.1f}s (ç½®ä¿¡åº¦: {best_point.confidence:.2f})")
                else:
                    # AIåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°è¯¥é›†çš„éšæœºç‚¹
                    episode = project.episodes[random_ep_idx]
                    if episode.duration:
                        max_offset = min(60.0, episode.duration / 3.0)
                        random_offset = round(random.uniform(0, max_offset), 3)
                    else:
                        random_offset = 0.0
                    
                    start_points.append((random_ep_idx, random_offset))
                    logger.info(f"âš ï¸ AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨éšæœºç‚¹: ç¬¬{random_ep_idx+1}é›†, {random_offset:.1f}s")
            
            return start_points
            
        except Exception as e:
            logger.error(f"AIç”Ÿæˆèµ·å§‹ç‚¹å¤±è´¥: {e}")
            return self._generate_random_start_points_with_dedup(project, count)
    
    def _generate_random_start_points_with_dedup(self, project: DramaProject, count: int) -> List[Tuple[int, float]]:
        """ç”Ÿæˆéšæœºèµ·å§‹ç‚¹ï¼Œæ”¯æŒå»é‡"""
        if not self.enable_deduplication:
            # å¦‚æœæœªå¯ç”¨å»é‡ï¼Œç›´æ¥è°ƒç”¨çˆ¶ç±»æ–¹æ³•
            start_points = super().generate_start_points(project, count)
            # è®°å½•ç”Ÿæˆçš„èµ·å§‹ç‚¹ï¼ˆä¸å»é‡ï¼Œä½†è®°å½•ç”¨äºåç»­å‚è€ƒï¼‰
            for ep_idx, timestamp in start_points:
                self._add_used_cut_point(ep_idx, timestamp)
            return start_points
        
        # å¯ç”¨å»é‡çš„éšæœºç”Ÿæˆé€»è¾‘
        start_points = []
        max_attempts = count * 10  # æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œé¿å…æ­»å¾ªç¯
        attempts = 0
        
        while len(start_points) < count and attempts < max_attempts:
            attempts += 1
            
            # ç”Ÿæˆä¸€ä¸ªéšæœºèµ·å§‹ç‚¹
            temp_points = super().generate_start_points(project, 1)
            if not temp_points:
                break
            
            ep_idx, timestamp = temp_points[0]
            
            # æ£€æŸ¥æ˜¯å¦ä¸å·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹å†²çª
            if not self._is_cut_point_excluded(ep_idx, timestamp):
                start_points.append((ep_idx, timestamp))
                self._add_used_cut_point(ep_idx, timestamp)
                logger.debug(f"ç”Ÿæˆéšæœºèµ·å§‹ç‚¹: ç¬¬{ep_idx+1}é›†, {timestamp:.1f}s")
            else:
                logger.debug(f"è·³è¿‡å†²çªçš„éšæœºèµ·å§‹ç‚¹: ç¬¬{ep_idx+1}é›†, {timestamp:.1f}s")
        
        if len(start_points) < count:
            logger.warning(f"å»é‡ååªç”Ÿæˆäº† {len(start_points)}/{count} ä¸ªèµ·å§‹ç‚¹")
        
        return start_points

    def _add_used_cut_point(self, episode_idx: int, timestamp: float):
        """è®°å½•å·²ä½¿ç”¨çš„å‰ªè¾‘ç‚¹"""
        self.used_cut_points.append((episode_idx, timestamp))
        logger.debug(f"è®°å½•å·²ä½¿ç”¨å‰ªè¾‘ç‚¹: ç¬¬{episode_idx+1}é›† {timestamp:.1f}s")
    
    def _reset_used_cut_points(self):
        """é‡ç½®å·²ä½¿ç”¨å‰ªè¾‘ç‚¹è®°å½•ï¼ˆç”¨äºå¤„ç†æ–°çš„é¡¹ç›®ï¼‰"""
        self.used_cut_points.clear()
        logger.debug("é‡ç½®å·²ä½¿ç”¨å‰ªè¾‘ç‚¹è®°å½•")
    
    def process_single_material(self, project: DramaProject, material_idx: int, 
                              start_ep_idx: int, start_offset: float, 
                              output_path: str, temp_root: str,
                              run_suffix: Optional[str], material_total: int, 
                              min_sec: float = 480, max_sec: float = 900) -> float:
        """é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œä½¿ç”¨AIç”Ÿæˆçš„èµ·å§‹ç‚¹è¿›è¡Œå¤„ç†"""
        logger.info(f"ğŸ¤– AIå¢å¼ºå¤„ç† | å‰§ï¼š{project.name} | ç¬¬ {material_idx} / {material_total} æ¡")
        logger.info(f"ğŸ¯ ä½¿ç”¨AIèµ·å§‹ç‚¹: ç¬¬{start_ep_idx+1}é›†ï¼Œåç§»{start_offset:.1f}ç§’")
        
        try:
            # ç›´æ¥ä½¿ç”¨AIåœ¨generate_start_pointsé˜¶æ®µç”Ÿæˆçš„ä¼˜åŒ–èµ·å§‹ç‚¹
            # ä¸å†è¿›è¡Œé‡å¤çš„AIåˆ†æï¼Œé¿å…åŒé‡è®¡ç®—
            
            # æ‰§è¡Œå¸¸è§„å¤„ç†æµç¨‹ï¼ˆä½¿ç”¨AIä¼˜åŒ–çš„èµ·å§‹ç‚¹ï¼‰
            logger.info("ğŸ“‹ å¼€å§‹æ‰§è¡Œè§†é¢‘å¤„ç†ï¼ˆåŸºäºAIä¼˜åŒ–çš„èµ·å§‹ç‚¹ï¼‰...")
            processing_time = super().process_single_material(
                project, material_idx, start_ep_idx, start_offset, 
                output_path, temp_root, run_suffix, material_total
            )
            
            # ä¿å­˜AIå¤„ç†å…ƒæ•°æ®
            if self.enable_scene_detection:
                self._save_ai_metadata(Path(output_path), {
                    'scene_detection_enabled': self.enable_scene_detection,
                    'ai_optimized_start_point': True,
                    'start_episode': start_ep_idx + 1,
                    'start_offset': start_offset,
                    'processing_timestamp': time.time()
                })
            
            logger.info(f"âœ… AIå¢å¼ºå¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return processing_time
            
        except Exception as e:
            logger.error(f"âŒ AIå¢å¼ºå¤„ç†å¤±è´¥: {e}")
            # é™çº§åˆ°å¸¸è§„å¤„ç†
            logger.info("ğŸ”„ é™çº§åˆ°å¸¸è§„å¤„ç†æ¨¡å¼")
            return super().process_single_material(
                project, material_idx, start_ep_idx, start_offset, 
                output_path, temp_root, run_suffix, material_total
            )
    
    def _find_optimal_segments_with_ai_for_episode(self, project: DramaProject, episode_idx: int) -> List[OptimalCutPoint]:
        """ä½¿ç”¨AIå¯»æ‰¾æŒ‡å®šé›†æ•°çš„æœ€ä½³å‰ªè¾‘ç‰‡æ®µ"""
        if not self.enable_scene_detection or not self.scene_analyzer or not project.episodes:
            return []
        
        if episode_idx >= len(project.episodes):
            logger.warning(f"é›†æ•°ç´¢å¼• {episode_idx} è¶…å‡ºèŒƒå›´ (æ€»å…± {len(project.episodes)} é›†)")
            return []
        
        try:
            # åˆ†ææŒ‡å®šé›†æ•°
            target_episode = project.episodes[episode_idx]
            logger.info(f"ğŸ“¹ AIåˆ†æç¬¬{episode_idx+1}é›†: {target_episode.file_path}")
            
            # ä½¿ç”¨AIåˆ†æå™¨å¯»æ‰¾æœ€ä½³å‰ªè¾‘ç‚¹
            optimal_points = self.scene_analyzer.find_optimal_cut_points(
                video_path=target_episode.file_path,
                target_duration=600,  # é»˜è®¤10åˆ†é’Ÿ
                min_duration=300,     # æœ€å°5åˆ†é’Ÿ
                max_duration=900      # æœ€å¤§15åˆ†é’Ÿ
            )
            
            # è¿‡æ»¤ä½è´¨é‡çš„å‰ªè¾‘ç‚¹ï¼ˆé™ä½é˜ˆå€¼ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°å‰ªè¾‘ç‚¹ï¼‰
            quality_threshold = 0.3  # é™ä½é˜ˆå€¼ä»0.6åˆ°0.3
            high_quality_points = [
                point for point in optimal_points 
                if point.confidence > quality_threshold
            ]
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            if not high_quality_points and optimal_points:
                logger.info(f"âš ï¸ ç¬¬{episode_idx+1}é›†ä½¿ç”¨{quality_threshold}é˜ˆå€¼æœªæ‰¾åˆ°å‰ªè¾‘ç‚¹ï¼Œé™ä½é˜ˆå€¼é‡è¯•...")
                quality_threshold = 0.1
                high_quality_points = [
                    point for point in optimal_points 
                    if point.confidence > quality_threshold
                ]
            
            logger.info(f"ğŸ¯ ç¬¬{episode_idx+1}é›†AIåœºæ™¯åˆ†æå®Œæˆ: {len(optimal_points)} -> {len(high_quality_points)} ä¸ªé«˜è´¨é‡å‰ªè¾‘ç‚¹ (é˜ˆå€¼: {quality_threshold})")
            return high_quality_points
            
        except Exception as e:
            logger.error(f"âš ï¸ ç¬¬{episode_idx+1}é›†AIåœºæ™¯åˆ†æå¤±è´¥: {e}")
            return []
    
    def _find_optimal_segments_with_ai(self, project: DramaProject) -> List[OptimalCutPoint]:
        """ä½¿ç”¨AIå¯»æ‰¾æœ€ä½³å‰ªè¾‘ç‰‡æ®µ - å…¼å®¹æ€§æ–¹æ³•ï¼Œé»˜è®¤åˆ†æç¬¬ä¸€é›†"""
        return self._find_optimal_segments_with_ai_for_episode(project, 0)
    
    
    
    
    def _save_ai_metadata(self, result_path: Path, metadata: dict):
        """ä¿å­˜AIå¤„ç†å…ƒæ•°æ®"""
        try:
            import json
            
            metadata_path = result_path.parent / f"{result_path.stem}_ai_metadata.json"
            
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"AIå…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜AIå…ƒæ•°æ®å¤±è´¥: {e}")
    
    def analyze_project_with_ai(self, project: DramaProject) -> dict:
        """ä½¿ç”¨AIåˆ†ææ•´ä¸ªé¡¹ç›®
        
        Args:
            project: çŸ­å‰§é¡¹ç›®
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        analysis_result = {
            'project_name': project.name,
            'total_episodes': len(project.episodes),
            'ai_recommendations': [],
            'optimal_segments_count': 0,
            'scene_analysis': {}
        }
        
        try:
            if self.enable_scene_detection and project.episodes:
                # åˆ†æä¸»è¦é›†æ•°
                main_episode = project.episodes[0]
                scenes = self.scene_analyzer.analyze_video_scenes(main_episode.file_path)
                
                # ç»Ÿè®¡åœºæ™¯ä¿¡æ¯
                high_quality_scenes = [s for s in scenes if s.quality_score > 0.7]
                analysis_result['scene_analysis'] = {
                    'total_scenes': len(scenes),
                    'high_quality_scenes': len(high_quality_scenes),
                    'average_scene_duration': sum(s.end_time - s.start_time for s in scenes) / len(scenes) if scenes else 0
                }
                
                analysis_result['ai_recommendations'].append(
                    f"æ£€æµ‹åˆ° {len(scenes)} ä¸ªåœºæ™¯ï¼Œå…¶ä¸­ {len(high_quality_scenes)} ä¸ªé«˜è´¨é‡åœºæ™¯"
                )
                
                # å¯»æ‰¾æœ€ä½³ç‰‡æ®µ
                optimal_points = self.scene_analyzer.find_optimal_cut_points(
                    main_episode.file_path, target_duration=600
                )
                analysis_result['optimal_segments_count'] = len(optimal_points)
                
                if optimal_points:
                    analysis_result['ai_recommendations'].append(
                        f"AIæ¨è {len(optimal_points)} ä¸ªæœ€ä½³å‰ªè¾‘ç‚¹ï¼Œå¯ç”Ÿæˆé«˜è´¨é‡çŸ­è§†é¢‘ç‰‡æ®µ"
                    )
                else:
                    analysis_result['ai_recommendations'].append("æœªæ‰¾åˆ°æ˜æ˜¾çš„åœºæ™¯å˜åŒ–ç‚¹ï¼Œå»ºè®®æ‰‹åŠ¨é€‰æ‹©å‰ªè¾‘ç‚¹")
        
        except Exception as e:
            logger.error(f"AIé¡¹ç›®åˆ†æå¤±è´¥: {e}")
            analysis_result['ai_recommendations'].append(f"AIåˆ†æå¤±è´¥: {e}")
        
        return analysis_result


# å·¥å‚å‡½æ•°
def create_ai_enhanced_processor(config: ProcessingConfig, 
                               enable_scene_detection: bool = True,
                               status_callback=None) -> AIEnhancedProcessor:
    """åˆ›å»ºAIå¢å¼ºå¤„ç†å™¨çš„å·¥å‚å‡½æ•°"""
    return AIEnhancedProcessor(
        config=config,
        enable_ai_scene_detection=enable_scene_detection,
        status_callback=status_callback
    )
